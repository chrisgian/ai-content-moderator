{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bad6be3",
   "metadata": {},
   "source": [
    "# Core Data Management Pipeline\n",
    "### Features:\n",
    "- From multiple sources (twitter, github, apis), do the following:\n",
    "- extract raw data (as-is) into the `data/raw` folder\n",
    "- prepare raw data and save as prepped data into the `data/prep` folder\n",
    "- assemble final data set and save it as the `data/final` folder\n",
    "\n",
    "\n",
    "### To-Do's:\n",
    "- MUST:\n",
    "    - Twitter data needs 2 steps: [1] extract label/tweet_id [2] query tweet_id for text\n",
    "- SHOULD:\n",
    "    - Better logging\n",
    "    - move common tools that i will use many times into a common.py file\n",
    "    - improved metadata on final dataset\n",
    "        - for example, is there treatment needed from multi-label perspective? if so this should be carried into the final dataset\n",
    "        - [tutorial: tweepy](https://medium.com/analytics-vidhya/fetch-tweets-using-their-ids-with-tweepy-twitter-api-and-python-ee7a22dcb845)\n",
    "- COULD:\n",
    "\n",
    "- WON'T: \n",
    "    - ML etl should not be in this notebook\n",
    "    - ETL on user handles? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f63217",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6accb50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize #package for flattening json in pandas df\n",
    "from datetime import datetime as dt\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b98e0",
   "metadata": {},
   "source": [
    "## TODO: Data Preparation Helpers\n",
    "\n",
    "- this is baseline, \"must transform\" data engineering ... preparation is only to standardize dataset into tabular format from disparate sources\n",
    "- this section does not do ML-style transformation related to feature engineering or enrichment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a60549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_current_time():\n",
    "    return dt.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# ------- data cleaning functions --------\n",
    "# data cleaning pipeline for hate-1:\n",
    "def hate_1_clean(df_raw):\n",
    "    return (\n",
    "        df_raw\n",
    "        [0]\n",
    "        .str.split(\":\",expand=True, n = 1)\n",
    "        .rename(columns = {0:'label', 1:'text'})\n",
    "        .assign()\n",
    "    )\n",
    "\n",
    "# data cleaning pipeline for hate-1:\n",
    "def hate_2_clean(df_raw):\n",
    "    return (\n",
    "    df_raw\n",
    "    .query(\"cn_id.str.startswith('EN')\", engine = 'python')\n",
    "    [['cn_id','hateSpeech','counterSpeech']]\n",
    "    .melt(id_vars = 'cn_id')\n",
    "    .assign(variable = lambda x: x.variable.replace({'hateSpeech':1,'counterSpeech':0}))\n",
    "    .query(\"value.duplicated() == False\", engine = 'python')\n",
    "    .drop(columns = 'cn_id')\n",
    "    .rename(columns = {'variable':'label','value':'text'})\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc856c",
   "metadata": {},
   "source": [
    "## TODO: Data Extraction Metadata\n",
    "\n",
    "- Purpose: This section tells the pipeline what to do and when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ac74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------- data source meatdata ------------\n",
    "extraction_meta = {    \n",
    "    'sexism_1':{\n",
    "        'type':'twitter',\n",
    "        'url_data':'https://raw.githubusercontent.com/ZeerakW/hatespeech/master/NAACL_SRW_2016.csv',\n",
    "        'url_gh':'https://github.com/ZeerakW/hatespeech',\n",
    "        'paper':None,\n",
    "        'prep_function':None\n",
    "    },\n",
    "\n",
    "    'hate_1':{\n",
    "        'type':'flat',\n",
    "        'url_data':'https://raw.githubusercontent.com/sjtuprog/fox-news-comments/master/annotated-threads/all-comments.txt',\n",
    "        'url_gh':'https://github.com/sjtuprog/fox-news-comments',\n",
    "        'paper':'https://arxiv.org/pdf/1710.07395.pdf',\n",
    "        'prep_function':hate_1_clean\n",
    "    },\n",
    "    \n",
    "    'hate_2':{\n",
    "        'type':'json',\n",
    "        'url_data':'https://raw.githubusercontent.com/marcoguerini/CONAN/master/CONAN/CONAN.json',\n",
    "        'parent_node':'conan',\n",
    "        'url_gh':None,\n",
    "        'paper':None,\n",
    "        'prep_function':hate_2_clean\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50eee8e",
   "metadata": {},
   "source": [
    "## TODO: Extraction Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c8fe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Extraction: -- dataset-id: sexism_1 -- type: twitter\n",
      "INFO:Extraction: -- dataset-id: hate_1 -- type: flat\n",
      "INFO:Extraction: -- dataset-id: hate_2 -- type: json\n",
      "INFO:Extraction:Filter Parent Node\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('Extraction')\n",
    "\n",
    "# keys are defined in json above\n",
    "for key in extraction_meta.keys():\n",
    "    # grab info from metadata\n",
    "    data_set_type = extraction_meta[key]['type']\n",
    "    url_data = extraction_meta[key]['url_data']\n",
    "    \n",
    "    logger.info(f\" -- dataset-id: {key} -- type: {data_set_type}\")\n",
    "    \n",
    "    # ----- JSON ----- #\n",
    "    if data_set_type == 'json':\n",
    "        # grab info from metadata\n",
    "        parent_node = url_data = extraction_meta[key]['parent_node']\n",
    "        \n",
    "        # request\n",
    "        payload = requests.get(extraction_meta[key]['url_data'])\n",
    "        content = payload.content\n",
    "        raw_json = json.loads(content)\n",
    "\n",
    "        if parent_node != None:\n",
    "            logger.info(f\"Filter Parent Node\")\n",
    "            raw_json = raw_json[parent_node]\n",
    "\n",
    "        extraction_meta[key]['df'] = pd.DataFrame(raw_json)\n",
    "        extraction_meta[key]['df'].to_csv(f\"./data/raw/{key}_raw_data.csv\",index = None)\n",
    "            \n",
    "    elif data_set_type == 'flat':\n",
    "        extraction_meta[key]['df'] = pd.read_table(extraction_meta[key]['url_data'], header=None)\n",
    "        extraction_meta[key]['df'].to_csv(f\"./data/raw/{key}_raw_data.csv\",index = None)\n",
    "    \n",
    "    elif data_set_type == 'twitter':\n",
    "        \"\"\"\n",
    "        will need to add more logic here to request twitter.\n",
    "        better idea to split this into two parts.\n",
    "        actual twitter extraction will be a big deal.\n",
    "        \"\"\"\n",
    "        extraction_meta[key]['df_twitter_id_labels'] = pd.read_table(extraction_meta[key]['url_data'], header=None)\n",
    "        extraction_meta[key]['df_twitter_id_labels'].to_csv(f\"./data/raw/{key}_twitterindex.csv\",index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9e821",
   "metadata": {},
   "source": [
    "## TODO: Data Prep Orchestration\n",
    "\n",
    "Working standards:\n",
    "- `label` is the column for truth values\n",
    "- `text` is column for raw feature\n",
    "\n",
    "Currently working:\n",
    "- For text based datasets \n",
    "\n",
    "\n",
    "Not started:\n",
    "- Twitter\n",
    "- Logging info\n",
    "- Logging important eda stuff like class imbalance or total n-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb95053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Extraction: -- dataset-id: sexism_1 -- type: json\n",
      "INFO:Extraction: -- dataset-id: hate_1 -- type: json\n",
      "INFO:Extraction: -- dataset-id: hate_2 -- type: json\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# for the entire extraction meta object\n",
    "for key in extraction_meta.keys():\n",
    "    \n",
    "    logger.info(f\" -- dataset-id: {key} -- type: {data_set_type}\")\n",
    "    \n",
    "    \n",
    "    # if applicable, apply a prep function and write the file out\n",
    "    if (extraction_meta[key].get('df',None) is not None):\n",
    "        (\n",
    "            extraction_meta[key]['prep_function'](extraction_meta[key]['df'])\n",
    "            .to_csv(f\"./data/prep/{key}_prepped.csv\",index = None)\n",
    "        )\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c2bad",
   "metadata": {},
   "source": [
    "## TODO: data assembly\n",
    "\n",
    "should haves:\n",
    "- more metadata? only dataset file name for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e292cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "fp_prep = './data/prep/'\n",
    "fp_final = './data/final/'\n",
    "\n",
    "prepped_data = list()\n",
    "for i in os.listdir(fp_prep):\n",
    "    if '_prepped' in i:\n",
    "        prepped_data_i = (\n",
    "            pd.read_csv(fp_prep + i)\n",
    "            .assign(\n",
    "                dataset = i\n",
    "            )\n",
    "        )\n",
    "        prepped_data.append(prepped_data_i)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "final_data = pd.concat(prepped_data)\n",
    "final_data.to_csv(f'{fp_final}clean_data_version_{get_current_time()}.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
